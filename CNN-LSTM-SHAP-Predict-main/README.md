# CNN-LSTM-Predict
AI financial price predict
The CNN_LSTM_predict file uses the CNN_LSTM model to perform feature extraction and comprehensive analysis on the prices of ten financial products related to BTC prices to predict the closing price of BTC.
# LSTM-Predict
The LSTM_predict file uses the LSTM model to perform feature extraction and comprehensive analysis on the prices of several financial products related to BTC prices, and uses the prices of the previous five days to predict the prices of the latest day.
Artificial Intelligence (AI) significantly improves time series forecasting in the financial market, yet it is challenging to establish reliable real-world finance applications due to a lack of transparency and explainability. This paper prototypes an explainable CNN-LSTM model that combines the advantages of CNN and LSTM (Long and Short Term) to train and forecast the price of Bitcoin using a group of 11 determinants. By avoiding information loss and information superposition, it combines long-term context information and short-term feature information to obtain comprehensive and accurate feature representation. Experiments show that CNN-LSTM generally has higher accuracy than a single LSTM network when processing and predicting Bitcoin sequence data, as measured by a mean absolute percentage error (MAPE) of 2.39% and an accuracy of 89.54%. Additionally, the CNN-LSTM model explains that trading volume and prices (Low, High, Open) contribute to the price dynamics, while oil and Dow Jones Index (DJI) influence the price behavior at a low level. We argue that understanding these underlying explanatory determinants may increase the reliability of AI’s prediction in the cryptocurrency and general finance market.
# SHAP
The contribution of the SHAP (Shapley Additive Explanations) algorithm in the above work is mainly reflected in the following aspects:
Explain model predictions: The SHAP algorithm provides explanations for model predictions by calculating the contribution of each feature to the model prediction results. It can help us understand how the model makes predictions based on input features, thereby enhancing the interpretability of the model.
 Feature importance analysis: The SHAP algorithm helps us understand the impact of each feature on model predictions by calculating the importance value of features. This helps us identify which features have a greater impact on the model’s predictions and thus better understand the relationship between the data and the model.  Visual interpretation results: The SHAP algorithm provides visualization tools, such as `shap.summary_plot` and `shap.force_plot`, which can visually display the importance of features and the feature importance of a single sample. This makes interpreting results easier to understand and communicate to others.
In general, the contribution of the SHAP algorithm in the above work is to provide an effective method to explain the prediction results of the model, help us understand the behavior of the model and the importance of features, thereby enhancing the interpretability and understandability of the model. reliability.
